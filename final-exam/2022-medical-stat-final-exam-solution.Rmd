---
title: "Medical Statistics 2^nd^ Semester Take Home Final Exam"
subtitle: "**Due Date: Dec 19 2022 (16:00) to Dec 23 2022 (23:59)**"
output: 
  pdf_document: 
    includes:
      in_header: header.tex
  keep_tex: true
  dev: "cairo.pdf"
  citation_pacakge: natbib
# bibliography: references.bib       
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
# knitr::opts_knit$set(root.dir = '..')
# library(officedown)
# library(officer)
# require(formatR)
# 
# fp <- fp_par(
#   text.align = "center", 
#   padding.bottom = 20, padding.top = 120, 
#   border.bottom = fp_border())
# 
# ft <- fp_text(shading.color='#EFEFEF', bold = TRUE)


options(max.print = 1000)
knitr::opts_chunk$set(eval = TRUE,
                      echo = FALSE,
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      tidy = TRUE,
                      tidy.opts = list(blank=TRUE, width.cutoff=60),
                      message = FALSE,
                      warning = FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = TRUE,
                      tab.topcaption = TRUE, 
                      fig.path="Figures/",  # Set the figure options
                      fig.align = "center",
                      fig.keep='all', fig.retina=2)
```

<br/> <br/>

**Name**: \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_

<br/> <br/>

## **Notice**

-   Please **DO SOLVE ANSWERS BY YOURSELVES!!**
-   You can use materials from other textbooks, lecture notes, and
    websites but you have to provide proper **CITATIONS**.
-   Write down your answers in the **MS Word Document** and save your word filename like [`student number-name.docx`, i.e. `202015015-boncho-ku.docx`]. it is admittable to submit your answers by converting your word file to pdf. 
-   If you make up your mind to submit your answers, send an E-mail to Dr. Boncho Ku and Dr. Mimi Ko with the attachment of your answer file.

## **Questions**

1.  Which one of the following statements is False?

    a)  The probability of a type II error is the probability that you
        reject the null hypothesis when it is true. then are followed to
        document occurrence of disease. (**FALSE**)

    b)  Subjects are enrolled or grouped on the basis of their exposure,
        then are followed to document occurrence of disease in
        prospective cohort study. (**TRUE**)

    c)  Especially when more than 20% of cells have expected frequencies
        \< 5, we need to use Fisher's exact test to determine if there
        are associations between two categorical variables. (**TRUE**)

    d)  To use the two-sample t-test, we need to assume that the data
        from both samples are normally distributed and they have the
        same variances. (**TRUE**)

    e)  In test for heterogeneity of meta-analysis, if Higgins $I^2\leq 25 \%$,
        studies are regarded homogeneous and the fixed effect model of
        meta-analysis can generally be used.bles. (**TRUE**)

\newpage

2.  There are five urns, and they are numbered 1 to 5. Each urn contains
    10 balls. Urn $i$ has $i$ defective balls and $10-i$ non-defective
    balls, $i=1,2,\ldots,5$. For example, urn 3 has three defective
    balls and seven non-defective balls. Consider the following random
    experiment: First an urn is selected at random, and then a ball is
    selected at random from the selected urn. Suppose that the
    experimenter does not know which urn was selected. Let's ask two
    questions.

    a)  What is the probability that a defective ball will be selected?

    b)  If we have already selected the ball and noted that it is
        defecvive, what is the probability that it came from urn 5?
        

**Solutions**

Let $A$ denote the event that a defective ball is selected and $B_i$ denote the event that urn $i$ is selected, $i=1,\ldots,5$. Then $P(B_i) = 1/5$ and $P(A|B_i) = i/10$, $i=1,\ldots,5$. Using the **theorem of total probabilities**, The solution of a) is 

$$
P(A) = \sum_{i=1}^{5} = P(A|B_{i})P(B_i) = \sum_{i=1}^{5}\frac{i}{10}\cdot \frac{1}{5} = \frac{1}{50}\sum_{i=1}^{5}i = \frac{15}{50} = \frac{3}{10}
$$

Employing Bayes' formula, the solution of b) is 

$$
P(B_5|A) = \frac{P(A|B_5)|P(B_5)}{\sum_{i=1}^{5} P(A|B_i)P(B_i)} = \frac{1/2\cdot 1/5}{3/10} = \frac{1}{3}
$$



3.  The distribution of grades in a large statistics course is as follows:

```{r}
library(tidyverse)
library(kableExtra)
library(flextable)

x <- c(0.1, 0.4, 0.3, 0.1, 0.1)
matrix(x, ncol = 5) %>% 
  as.data.frame -> x
names(x) <- LETTERS[c(1:4, 6)]
  
h <- tibble(`Grade:` = c("Probability"))
tibble(h, x) %>% 
  kbl(booktabs = TRUE, 
      escape = FALSE, 
      align = "lccccc") %>% 
  kable_styling(
    position = "center", 
    latex_options = c("hold_position")
  )
  
```

To calculate student grade point averages, grades are expressed in a
numerical scale with A=4, B=3, and so on down to F=0.

a)  Find the expected value.

b)  Describe your strategy to **simulate** choosing students at random
    and recording their grades.

c)  Based on your strategy described in b), perform the simulation with
    a sample size of size 30 and calculate the mean of their 30 grades
    **using R**.

d)  Repeat c) 10,000 times and calculate the average of 10,000 means.

e)  Make a histogram of 10,000 means.

f)  Describe your conclusion based on the results of a) to e).

<!-- -->
<!-- \vspace{0.5cm} -->

**Solutions**

Let $X$ be a random variable representing numerical points for each grade. The solution of a) is $E(X) = 0.1\cdot 4 + 0.4\cdot 3 + 0.3\cdot 2 + 0.1\cdot 1 + 0.1\cdot 0 = 2.3$

Using `sample()` function implemented in R, we can generate synthetic samples with the assignment of the given probabilities and scores for grades. For example, we assume that 30 students are randomly selected from the given probability distribution of grades with replacement. Then we simply write down scripts as follows (solution b) to c)). 

```{r, echo=TRUE}
set.seed(20221225) # for the reproducibility
p <- c(0.1, 0.4, 0.3, 0.1, 0.1)
x <- 4:0

xi <- sample(x, size = 30, replace = TRUE, prob = p)
mean(xi)

```

For the solution d) to e), 

```{r, echo=TRUE}
N <- 10000; n <- 30
p <- c(0.1, 0.4, 0.3, 0.1, 0.1)
x <- 4:0

m_grade <- integer(N)
set.seed(20221225)
for (i in 1:N) {
  s <- sample(x, size = n, replace = TRUE, prob = p)
  m_grade[i] <- mean(s)
}

mean(m_grade)
hist(m_grade)

```

We generate 10,000 independent samples of grade scores with a size of 30 and calculate sample means for each sample. Therefore we obtain 10,000 sample means and their distribution is approximately normal. Furthermore, the empirical mean of sample means is almost close to the theoretical expectation of grade scores with the given distribution.


4.  Describe the relationship between Pearson's correlation coefficients
    and the regression coefficient (slope) of univariate regression
    analysis. You're definitely able to refer to the Internet or other
    textbooks but you have to give descriptions or formulas in your own
    words and cite appropriately.
    

**Solutions**

The simple (univariate) regression model for $n$ observation can be written as 

$$
y_i = \beta_0 + \beta_{1}x_i + \epsilon_i, ~~~ i = 1, 2, \ldots, n
$$

where $E(\epsilon_i) = 0$, $\mathrm{Var}(\epsilon_i) = \sigma^2$ for all $i=1,2,\ldots,n$ and $\mathrm{Cov}(\epsilon_i, \epsilon_j) = 0$ for all $i \neq j$. To estimate unknown parameter $\beta_0$ and $\beta_1$ that minimize the sum of squares of the deviations $y_i - \hat{y}_i$ of the $n$ observed $y_i$'s from their predicted values $\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1x_i$, the **_least squares_**^[Please check it] approach can help find the solution. The solution of $\hat{\beta}_0$ and $\hat{\beta}_1$ is 

$$\begin{aligned}
\hat{\beta}_1 &= \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2} \\
\hat{\beta}_0 &= \bar{y} - \hat{\beta}_{1}\bar{x}
\end{aligned}$$


Recall that the Pearson's correlation coefficients ($\hat{\rho}_{xy}$) between two variables $x$ and $y$ is

$$
\hat{\rho}_{xy} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n (x_i - \bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}
$$

The slope of the regression line $\hat{\beta}_1$ can be rewritten as 

$$
\hat{\beta}_1 = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n (x_i - \bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}} \frac{\sqrt{(y_i - \bar{y})^2/(n-1)}}{\sqrt{(x_i - \bar{x})^2/(n-1)}} = \hat{\rho}_{xy}\frac{s_{y}}{s_x}
$$

where $s_{x}$ and $s_y$ are standard deviation of $x$ and $y$, respectively. 

When we developed the regression model, we need a statistical measurement to examine how the explanatory variable $x$ is well predictable to the response variable. In this context, the coefficient of determination $R^2$ plays an important role to assess the regression model performance. $R^2$ is defined as the proportion of the variance explained by the independent variables, relative to the total variance in the data. This can be quantified as the ratio of explaned sum of squares to total sum of squares. 

$$
R^2 = \frac{SSR}{SST}, ~~~ SSR = \sum_{i=1}^{n}(\hat{y}_i - y_i)^2, ~~~ SST = \sum_{i=1}^{n} (y_i - \bar{y})^2
$$

Using the solution of the least squares for regression coefficients, 


$$
\begin{aligned}
R^2 &= \frac{\sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \\
    &= \frac{\sum_{i=1}^{n} (\hat{\beta}_0 + \hat{\beta}_1 x_i - \bar{y})^2} {\sum_{i=1}^{n} (y_i - \bar{y})^2} = \frac{\sum_{i=1}^{n} (\bar{y} - \hat{\beta}_1 \bar{x} + \hat{\beta}_1 x_i - \bar{y})^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} \\
    &= \frac{\sum_{i=1}^{n} \left( \hat{\beta}_1 (x_i - \bar{x}) \right)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2} = 
    \hat{\beta}_1^2 \, \frac{\frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2}{\frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y})^2} \\
    &= \hat{\beta}_1^2 \, \frac{s_x^2}{s_y^2} = \left( \frac{s_x}{s_y} \, \hat{\beta}_1 \right)^2
\end{aligned}
$$


Using the relationship between the correlation coefficient and the regression slope estimate, 

$$
R^2 = \left( \frac{s_x}{s_y} \, \hat{\beta}_1 \right)^2 = \hat{\rho}^2_{xy}
$$

5.  The attached data file(`P5-passive-avoidance.xlsx`) represents the results of the passive-avoidance
    test to evaluate the protective effects of the MC treatment on
    scopolamine-induced memory impairments in mice. The experiment
    considers four levels of the treatment; `Control`, `Scopolamine`
    (memory impairment), `MC-420` (scopolamine impairment + MC 420
    $\mathrm{mg/kg}$), and `MC-840` (scopolamine impairment + MC 840 $\mathrm{mg/kg}$).
    The values in the data represent the ratio of retention and
    acquisition (retention/acquisition \* 100 (%)). Perform your own
    data analysis **using R** (_**Hint**_: for the analysis, you may need to
    transform the original data).


\begin{quote}
\colorbox{gray!10}{\begin{minipage}{15cm}
\textbf{Notice}

The following scripts and results are the most canonical way to perform the one-way ANOVA test. The students' solutions may differ but that is very normal. The scoring for students' answers will be based on what you've learned in the semester. The presented scripts and analysis results have been disclosed for reasonable use by students when performing data analysis (especially performing ANOVA analysis). 
\end{minipage}}
\end{quote}


**Solutions**
    
```{r, echo=TRUE}
## read dataset
library(tidyverse)
library(readxl)

pa_dat <- read_xlsx("final-exam/P5-passive-avoidance.xlsx")

# simple preprocessing: character -> factor
pa_dat2 <- pa_dat %>% 
  pivot_longer(cols = -case_num, 
               names_to = "treatment") %>% drop_na %>% 
  mutate(
    treatment = factor(treatment, levels = c("Control", "Scopolamine", "MC-420", "MC-840"))
  )

```

Descriptive Statistics 

```{r, echo=TRUE, tidy=TRUE}
pa_dat2 %>% 
  group_by(treatment) %>% 
  summarise(
    N = n(), Mean = mean(value), 
    SD = sd(value), 
    Min = min(value), 
    Median = median(value), 
    IQR = IQR(value), 
    Max = max(value)
  )

```

Check Normality: Q-Q plot

```{r, echo=TRUE, fig.height=10, fig.width=10, fig.pos="H", out.width="10cm", out.height="10cm"}
library(broom)
library(ggpubr) # ggplot for the publication
## generage Q-Q plot
ggqqplot(pa_dat2, x = "value", color = "treatment", group = "treatment", 
         facet.by = "treatment", palette = "lancet", 
         ggtheme = theme_pubclean(base_size = 12))

```


Check Normality: Shapiro-Wilk's Test

```{r, echo=TRUE}
# Shapiro-Wilk's Normality test for each group
pa_dat2 %>% 
  group_by(treatment) %>% 
  nest %>% 
  mutate(norm_test = 
           map(data, ~ shapiro.test(.x$value))) %>% 
  mutate(
    norm_test = map(norm_test, tidy)
  ) %>% 
  select(norm_test) %>% 
  unnest(norm_test)


```

The data of Scopolamine and MC-840 do not satisfy the normality assumption. Consider the log transformation and check the normality again. 

```{r, echo=TRUE, fig.height=10, fig.width=10, fig.pos="H", out.width="10cm", out.height="10cm"}
# add log-transformed data
pa_dat2 <- pa_dat2 %>% 
  mutate(log_value = log(value))
## generage Q-Q plot
ggqqplot(pa_dat2, x = "log_value", color = "treatment", group = "treatment", 
         facet.by = "treatment", palette = "lancet", 
         ggtheme = theme_pubclean(base_size = 12))

```


```{r, echo=TRUE}
# Shapiro-Wilk's Normality test for each group
pa_dat2 %>% 
  group_by(treatment) %>% 
  nest %>% 
  mutate(norm_test = 
           map(data, ~ shapiro.test(.x$log_value))) %>% 
  mutate(
    norm_test = map(norm_test, tidy)
  ) %>% 
  select(norm_test) %>% 
  unnest(norm_test)

```

The values after the log transformation suffice the normality. Perform One-way ANOVA test for the log-transformed data.

```{r, echo=TRUE, results='asis'}
aov_res1 <- lm(value ~ treatment, data = pa_dat2) %>% anova
aov_res2 <- lm(log_value ~ treatment, data = pa_dat2) %>% anova

# print table in pdf document
options(xtable.comment = FALSE)
tbl1 <- xtable::xtable(aov_res1, 
                       caption = "ANOVA table for the original data")
tbl2 <- xtable::xtable(aov_res2, 
                       caption = "ANOVA table for the log transformed data")
print(tbl1, caption.placement = "top", table.placement = "H")
print(tbl2, caption.placement = "top", table.placement = "H")

```

The log transformed data show the statistical significance at $\alpha = 0.05$. Therefore, the further analysis fill proceed based on the log-transformed data. 

Since the analysis aims to investigate the protective effect of MC treatment for scopolamine-induced memory impairment, the baseline level should be the `Scopolamine` group. The comparison for the group differences compared to the baseline level (`Scopolamine`) is performed rather than multiple comparisons for all pairs of groups to prevent the over-adjustment for type I error. For this purpose, we conduct Dunnett's test for the multiple comparison. 


```{r, echo=TRUE}
# Multiple Comparison: Dunnett's Test #
# Based on log-transformed data
library(emmeans) # a package for estimating marginal mean
pa_dat2$treatment2 <- relevel(pa_dat2$treatment, ref = "Scopolamine")
mod <- lm(log_value ~ treatment2, data = pa_dat2)
emm <- emmeans(mod, ~ treatment2)
emm_cont <- contrast(emm, method = "trt.vs.ctrl", adjust = "dunnett")
emm_cont %>% tidy(conf.int = TRUE) %>% 
  mutate_at(
    vars(null.value:std.error, contains("conf.")), exp
  ) %>% 
  select(-c(term, null.value, df))

```


- The retention/acquisition of the control group was 2.79 times higher than that of the scopolamine-induced memory impairment group (p = 0.0255) $\rightarrow$ Scopolamine works properly in terms of reduciing memory ability in mice
- The retention/acquisition of the MC-840 group was 2.96 times higher than that of the scopolamine-induced memory impairment group (p = 0.0237) $\rightarrow$ The high dose of MC treatment protects the memory impairment in mice



```{r, echo=TRUE, fig.height=7, fig.width=9, fig.pos="H", out.width="11cm", out.height="15cm"}
## A Tip for making a graphpad bar graph style 
## tables below the barplot
Rows <- c("MC (mg/kg)", "Scopolamine (1 mg/kg)")
group <- levels(pa_dat2$treatment)
l1 <- rep("―", 2); l2 <- c("―", "+"); l3 <- c("420", "+")
l4 <- c("840", "+")
tab <- data.frame(Rows, l1, l2, l3, l4)

names(tab) <- c("rows", group)
tab %>% 
  pivot_longer(cols = -rows) %>% 
  mutate(name = factor(name, levels = group), 
         rows = factor(rows, levels = Rows)) %>% 
  ggplot(aes(x = name)) + 
  geom_text(aes(y = reorder(rows, desc(rows)), label = value), size = 4.5, 
            family = "sans") + 
  labs(y = "", x = NULL) + 
  theme_minimal(base_size = 15, base_family = "sans") + 
  theme(axis.line = element_blank(), 
        axis.ticks = element_blank(), 
        axis.text.x = element_blank(),
        panel.grid = element_blank(), 
        strip.text = element_blank(), 
        axis.text.y = element_text(color = "black",  
                                   size = 12)) -> p_tab

## make barplot
library(ggthemes) # a package for ggplot themes
library(patchwork) # a package for merging multiple ggplot

# generating the dataset for making barplot
emm_tidy <- emm %>% tidy(conf.int = TRUE)
cont_tidy <- emm_cont %>% 
  tidy(conf.int = TRUE) %>% 
  separate(contrast, c("group", "ref"),
             sep = " - ") %>%
    mutate(group = gsub("\\(|\\)", "", group)) %>%
    select(-term)  

fill_cols <- "#707070"
group_lev <- c("Control", "Scopolamine", "MC-420", "MC-840")

emm_tidy %>% 
  left_join(cont_tidy, by = c("treatment2" = "group")) %>% 
  mutate(treatment2 = factor(treatment2, levels = group_lev)) %>%
  ggplot() +
  aes(x = treatment2, y = exp(estimate.x)) +
  geom_errorbar(aes(ymin = exp(estimate.x) - exp(estimate.x) * std.error.x,
                    ymax = exp(estimate.x) + exp(estimate.x) * std.error.x),
                width = 0.2, linewidth = 1) + 
  geom_bar(stat = "identity", width = 0.6,
           fill = fill_cols) +
  scale_y_continuous(expand = expansion(mult = c(0, 0)), 
                     limits = c(0, 350),
                     breaks = seq(from = 0, to = 350, by = 50)
                     ) +
  geom_text(aes(x = 1, y = Inf, label = "F = 3.852 (df1 = 3, df2 =26); p-value = 0.021"), 
            vjust = 1, hjust = 0) + 
  geom_segment(x = 1, xend = 2, y  = 275, yend = 275, 
               arrow = arrow(#angle=90, 
               type = "closed", 
               length = unit(0.1, "cm"), 
               ends = "both"), 
               lwd = 0.7, 
               lty = 1, 
               colour = "gray") + 
  geom_text(aes(x = 1.5, y = 275, label = "p = 0.026"), 
            hjust = 0.5, vjust = -0.5) + 
  geom_segment(x = 2, xend = 4, y  = 300, yend = 300, 
               arrow = arrow(#angle=90, 
               type = "closed", 
               length = unit(0.1, "cm"), 
               ends = "both"), 
               lwd = 0.7, 
               lty = 1, 
               colour = "gray") +   
  geom_text(aes(x = 3, y = 300, label = "p = 0.024"), 
            hjust = 0.5, vjust = -0.5) + 
  labs(y = "Retention/Acquisition (%)", x = NULL) + 
  theme_tufte(base_size = 15, base_family = "sans") + 
  theme(axis.text.x = element_blank(), 
        axis.ticks.x = element_blank(), 
        axis.title.y = element_text(vjust = -30, face = "bold"),
        axis.line = element_line(colour="black", size = 1), 
        axis.ticks.y = element_line(colour="black", size = 1), 
        axis.text.y = element_text(color = "black")) -> p1

# merge pos/neg table and barplot
p1/p_tab + plot_layout(heights = c(9, 1))

```




6.  A total of 160 men of different ethnic backgrounds were included in
    a cross-sectional study of factors related to blood clotting. We
    compared mean platelet levels in the four groups using a one-way
    ANOVA. It was reasonable to assume Normality and constant variance.

```{r, echo=FALSE, message=FALSE}
tab1 <- tibble(
  Group = c(
    "Caucasian",
    "Afro-Caribbean",
    "Mediterranean",
    "Other"
  ),
  `N (\\%)` = c(
    "100 (62.5)",
    "18 (11.3)",
    "23 (14.4)",
    "19 (11.9)"
  ),
  `Mean($\\times 10^9$)` = c(
    "268.1",
    "254.3",
    "281.1",
    "273.3"
  ),
  `SD ($\\times 10^9$)` = c(
    "77.08",
    "67.50",
    "71.09",
    "63.42"
  )
)

kbl(tab1,
    booktabs = TRUE,
    escape = FALSE,
    align = "lccc") %>%
  kable_styling(
    position = "center",
    latex_options = c("hold_position"),
    full_width = FALSE
  )
  

```

Fill the following ANOVA table

```{r}
tab2 <- tibble(
  Source = c(
    "Between Group", 
    "Within Group", 
    "Total"
  ), 
  SS = c(
    "9333.0", 
    "966108.0", 
    "975441.0"
  ), 
  DF = c(
    "(1)", 
    "(2)", 
    " "
  ), 
  MS = c(
    "(3)", 
    "(4)", 
    " "
  ), 
  "F-ratio" = c(
    "(5)", 
    " ", 
    " "
  ), 
  "P-value" = c(
    "0.423", 
    " ", " "
  )
)

kbl(tab2, 
    booktabs = TRUE, 
    escape = FALSE, 
    align = "lccccc") %>% 
  kable_styling(
    position = "center",
    latex_options = c("hold_position"), 
    full_width = FALSE
  )
  

```


**Solutions**

(1) $df_B = \mathrm{\#~of~groups} - 1 = 4 - 1 = 3$
(2) $df_E = \mathrm{Total~N} - \mathrm{\#~of~groups} = 160 - 4 = 156$
(3) $MSB = SSB/df_B = 9333.0/3 = 3111.0$
(4) $MSE = SSW/df_E = 966108.0/156 = 6193.0$
(5) $F = MSB/MSE - 0.502$


7.  Calculate the sample size for the following questions.

<!-- -->

a)  An active-controlled randomized trial proposes to assess the
    effectiveness of Herbal medicine A in reducing pain. A previous
    study showed that Herbal medicine A can reduce pain score by 5
    points from baseline to week 24 with a standard deviation ($\sigma$)
    of 1.195. A clinically important difference of 0.5 as compared to
    active drug is considered to be acceptable. (Level of significance =
    5%, Power = 80%, Type of test =two-sided)

b)  A placebo-controlled randomized trial proposes to assess the
    effectiveness of Drug A in curing infants suffering from sepsis. A
    previous study showed that proportion of subjects cured by Drug A is
    50% and a clinically important difference of 16% as compared to
    placebo is acceptable. (Level of significance = 5%, Power = 80%,
    Type of test =two-sided)
    
    
**Solutions**

a) $\alpha = 0.05$, $1-\beta = 0.8$, $\sigma = 1.195$, and $\delta = 0.5$. Then effect size is $\eta = 0.5/1.195 = 0.418$. Then sample size can be obtained with the following formula: 

$$
n = \frac{2(Z_{1 - \alpha/2} + Z_{1-\beta})^2}{\eta^2} = \frac{2*(1.96 + 0.84)^2}{0.418^2} \approx 90
$$


b) Suppose $\theta_1 = 0.5$ and $\theta_2 = 0.34$. Then 


$$
n = \frac{(z_{1-\alpha/2} + z_{1-\beta})^2[\theta_1(1-\theta_1) + \theta_2(1-\theta_2)]}{(\theta_1 - \theta_2)^2} = 
\frac{(1.96 + 0.84)^2(0.5(1-0.5) + 0.34(1-0.34))}{(0.16)^2} = 145.29 \approx 146
$$



